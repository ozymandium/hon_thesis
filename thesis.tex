\documentclass[12pt]{report}
\usepackage{auhonors}

\usepackage{ulem}
\usepackage{url}
\usepackage{tikz}
\usepackage{pgf}

% enable expand math support
\usepackage{amsmath}
% enable graphic support
\usepackage{graphicx}

% table stuff
% \usepackage{array}
% \newcolumntype{$}{>{\global\let\currentrowstyle\relax}}
% \newcolumntype{^}{>{\currentrowstyle}}
% \newcommand{\rowstyle}[1]{\gdef\currentrowstyle{#1}%
%   #1\ignorespaces
% }

% for list of abbreviations
\usepackage[intoc]{nomencl}
\renewcommand{\nomname}{List of Abbreviations}
\makenomenclature
%% don't forget to run:   makeindex ausample.nlo -s nomencl.ist -o ausample.nls


% click on links to jump in pdf - should come last of usepackages
\usepackage{hyperref}
\hypersetup{}

% May want theorems numbered by chapter
% \newtheorem{theorem}{Theorem}[chapter]

\title{A Visual Driver Aid and Investigation of Error Propagation in Convoy Following Based on Dynamic Base Real-Time Kinematic Positioning}
\author{Robert Grissom Cofield}
\date{May 5, 2013}
\copyrightyear{2013}
\adviser{David M. Bevly}

\professor{David Bevly \\ Professor \\ Mechanical Engineering}
\professor{Kathie Maddox \\ Associate Director \\ Honors College}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   Prefatory Pages
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{romanpages}

\ApprovalPage
\TitlePage
\CopyrightPage

\begin{vita}%\def\romanpages{0}
Robert Cofield ...
\end{vita}


\begin{abstract}
Abstract goes here ...
\end{abstract}


\begin{acknowledgments}
Thank people here ...
\end{acknowledgments}


\style{ASME}
\software{
    \LaTeX,
    Python v2.7.3,
    MOOS v10,
    pyMOOS,
    Qt v4.8.3,
    Qt4 Designer,
    PySide v1.1.1,
    tornado v2.3,
    Google Earth v7.0.3.8542,
    simplekml v1.2.1
}
\StylePage

\tableofcontents
\listoffigures
\listoftables

\printnomenclature[0.75in] 

\end{romanpages}

\normalem       % Make italics the default for \em


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   Chapter 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}

% Establish the use case
The convoy scenario is examined, wherein a chain of vehicles are aligned front to back along some path determined by the front-most vehicle. Each inner vehicle acts as a leader to that following it, and follows the one preceding it. As such, vehicle must maintain some form of communication with those directly adjacent to it.
The computational tasks for each leader-follower pairing is carried out in the following vehicle. This is typically done in the lead vehicle for other secenarios, such as when the follower is an unmanned aerial vehicle, as UAV's are often limited by weight, and thus outsource processing tasks to ground computers where possible. Relying on the leader for positioning data is even used for swarm setups with a single leader and multiple followers \cite{gian}, regardless of the positioning method. For the present scenario, however, this structure makes the implementation of visualization software for data recieved from each leader much easier to implement with a low computational cost. The following chapter highlights why a navigational aid is necessary for convoy scenarios, why DRTK with TDCP is the ideal solution, and how it functions.

\section{Motivation} %% GET CITATIONS!
%Autonomous scenarios?
% military convoys
The military often uses long trains of transport vehicles to move supplies and munitions through perilous terrain over long distances. Landmines and other explosive roadside devices are common in many combat environments, and a precise path of safe travel may be defined. Rather than use at least one soldier to operate each vehicle, having a single human driver in the lead would reduce manpower and, potentially, casualties in the event that a convoy is attacked. In addition, a machine-driven following vehicle can potentially acheive much greater lateral path following accuracy than a human-driven vehicle.

% commercial trucking
Commercial trucking accounts for XXXXX of all vehicles on the road. In areas where traffic congestion is a serious problem, automation of the driving task could allow for tighter truck groupings, easing congestion and avoiding vehicular collisions. When extremely close together, vehicles experience the aerodynamic phenomenon known as `drafting', whereby the air drag created by a lead vehicle clears the way for those following it, thereby lessening the total force required to propel the vehicle and significantly lowering fuel consumption. In addition, driver `down time'---when truck drivers must rest periodically and stop the vehicle---could almost be eliminated by placing drivers in two to three trucks and having them take turns as the leader of the convoy, resting and allowing the automated following system to control their truck. This would also drastically reduce the labor required to move goods via the highway system

%%%%%%%%%%%%%%%%%%%
% COMPARE SOLUTIONS
\section{Comparison of Positioning Solutions for Real-Time Following}
An abundance of alternatives exist for positioning one vehicle behind another. Many incorporate fusion algorithms, wherein data from multiple sensors providing the same information is intelligently assigned varying weights in the determination of an overall solution. In addition, coupling sensors with complimentary strengths (e.g., IMU and GPS) has proven to be an extremely robust and effective method of localization and navigation \cite{scottthesis}. The following section will overview the strengths and weaknesses of each as a standalone sensor employed for vehicular following as compared DRTK/TDCP.

%%%% RANGING
\subsection{Ranging Devices}
Ranging devices operate on a similar principle to GPS pseudoranging, the time-of-flight. A signal of some type is emitted from the ranging instrument and reflected off some object. Many of the signals return to the ranging device, whereupon the elapsed time is multiplied by the speed of the signal to yield a range. These all require that the object to be detected be visible to the instrument, or have a direct line of sight. While useful in many situations, the present scenario does not always provide for direct line of sight.

% RADAR - finished
The most popular of these technologies is Radio Dectection and Ranging (RADAR), which came to prominence during WWII, and is widely used for adaptive cruise control (ACC) in the automotive industry. The scenario of ACC is similar to the present scenario in that relative positioning is employed to monitor the location of a vehicle travelling directly ahead along a comparable path. The primary goal is to sustain a target forward velocity until doing so would result in a rear-end collision.  RADAR is capable of detecting the kinematic movement of multiple objects within its field of view, but must maintain line-of-sight \cite{lidarvsradaracc}. This does well for avoidance scenarios, but the present objective---while avoiding a rear-end collision is desirable---is quite the opposite.

% SONAR - finished
The simplest implementation of this concept is Sonic Navigation and Ranging (SONAR). Sound waves are emitted and upon return, the calculated distance indicates an object at the determined range somewhere within the field of the emitter. As this provides no orientation, arrays of SONAR devices must often be used to successfully avoid obstacles. This may be combined with odometry to some effect, but navigation is very difficult and highly imprecise.

% LiDAR - finished
Light Detection and Ranging (LiDAR) allows measurement of not only a very precise position, but the optical properties of the detected object. A beam of light is emitted and reflected back to the instrument, whereupon the elapsed time is multiplied by the speed of light to yield a range. For relative positions to be accurate, either mounting of the instrument must be extremely precise or a calibration process is required \cite{jordanlidar}. Once properly tuned, LiDAR may produce errant readings during inclement weather, and also necessitates the adjacent leader to be within line-of-sight for any useable data to be returned. On the other hand, LiDAR also yields a numerical value for the intensity of the objects which are visible, which can be used to determine lateral path deviation provided that lane markings are visible and the path lies within them \cite{cameralidarlane}. 

%%%% VISION
\subsection{Vision}
Convoy following algorithms based on computer vision has existed for quite some time \cite{visionrec}, and like LiDAR lends itself to lane-level positioning, but requires a line-of-sight for any data on the intended leader. Camera systems are also susceptible to direct sunlight, rain, and poor illumination, which in many cases render the system useless. The use of a graphics processing unit is often required, as image processing tasks are computationally expensive, sometimes prohibitively so for embedded systems.
% Mono Camera
A monocular camera employed for the present purposes will typically extract notable features from a rectangular image. To make determination of the leader's pose less error-prone, an easily extractable object of known shape and dimensions can be placed on the rear of the vehicle where it can be seen by the follower camera.
% Stereo Camera
Stereo cameras function much like the human eye, in that depth is obtained from comparing differences between two images of the same object taken simultaneously from two cameras of aligned in parallel at a known separation in the direction perpendicular to the line-of-sight.


%%%%%%%%%%%%%%
% Explain GNSS
\section{Global Navigation Satellite System}

% \subsection{Principles of GNSS}
At the fundamental level, GNSS
\footnote{GNSS is a protocol-agnostic term referring to any of several constellations worldwide which use satellites to provide a receiver on the ground with position information. The US implementation is known as GPS, the Russian positioning system is referred to as GLONASS, and the European Union has Galileo.}
comprises a constellation of orbitting satellites whose positions above the earth are known, corresponding with a receiver to give as many range measurements as possible so that a global 3 dimensional location may be calculated. GNSS does not necessitate line of sight, and is not impaired by lighting effects, though a clear view of the sky is needed to connect to as many satellites as possible. The range for highly accurate following is large, on the order of kilometers depending upon speed, and lower accuracy following can be performed for two vehicles at any distance. These make GNSS ideal for use in the leader-follower convoy scenario.

% Improvements to standalone
% RTK - finished
Oftentimes, when working in a defined area, the exact location of a nearby point is known. If this is not the case, the exact location of a point may be found by setting up a static GPS receiver and allowing the measurements to average towards zero error over a long period of time. Once the precise location is known, the base station can transmit the difference between this value and the position received by standalone GPS to nearby receivers in real-time. Using these corrections to compensate for errors is known as Real Time Kinematic (RTK) GPS. It produces extremely accurate global positioning (i.e., in the earth coordinate frame).
% DRTK
RTK assumes that two receivers will experience similar errors when in close proximity and measuring simultaneously. The same principal applies to two receivers when both are kinematically active, but a globally accurate position is no longer possible without some reference. Instead, a high-accuracy relative position vector (RPV) can be obtained by subtracting the position of one receiver from that another at the same time epoch.
% TDCP
This practice of subtracting errors can be extended to work with a single receiver. Between very successive measurment epochs taken in short periods, many of the errors in standard GPS remain constant. The corresponding time difference of the carrier phase (TDCP) can then be used to calculate a change in position between time steps, also known as odometry \cite{travisdiss}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% How we get what's on the screen
\section{Position Using the DRTK and TDCP Algorithms}
Figure \ref{fig:drtktdcp} illustrates how information is taken from each receiver to obtain the information necessary for the display. The algorithms used to calculate information displayed by the GUI have been developed extensively by \cite{scottthesis},\cite{travisshort}, \cite{travisconvoy} and \cite{travisdiss}. The Driver Assisted Following (DAF) algorithm adds odometry from the TDCP algorithm to RPVs from the DRTK algorithm to obtain a set of points in the East-North-Up (ENU) coordinate frame---with the origin at the follower---which lie along the path taken by the leader. Distance between relative path points depends upon the velocity of the leader and the frequency of the slowest algorithm. The specifications of all hardware used are outlined in Chapter \ref{chap:exper}.

% flowchart - How the data gets from receiver to gui
\begin{figure}[ht]
    \centering
    \includegraphics[width=6.5in]{./figs/data_algo.png}
    \caption{Relative path determination processes}
    \label{fig:drtktdcp}
\end{figure}

%%%% ACCURACY
% \subsection{Accuracy}
% \label{sec:theoacc}
% DRTK accuracy - finished
The accuracy of DRTK GPS is primarily contingent upon the availability of dual-band (L1 and L2, rather than L1 only) signals, and of high precision ambiguity estimates (fixed integer rather than floating point). Under ideal conditions, the root-mean-square error of DRTK positions will be as low as $0.33~cm$ with a variance of $0.10~cm^2$. 
% TDCP accuracy 
The accuracy of the TDCP algorithm decreases over time as errors in the position changes accumulate. The mean time for a static receiver to accumulate $1.0~m$ lateral error is $378~s$, so the curvilinear distance at which this error will be present is contingent upon the speed of the follower. A complete analysis of the DRTK/TDCP algorithm error behavior is provided by \cite{scottthesis}. The combined accuracy traits of the system when employed for convoys of three or more vehicles are explored in Chapter \ref{chap:errprop}.
% Combined output of TDCP and DRTK for path
% Velocity accuracy





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   Chapter 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Graphical User Interface} \label{chap:gui}

%%%%%%%%%%%%%%
% Introduction
\section{Introduction} \label{sec:guiintro}

%%%% Role of the GUI
Before beginning creation of the GUI, a very high level analysis of its role was performed---it was treated as a `black box' system to define inputs and outputs. Neighboring systems were consolidated into singular systems so that interfaces could be designed to robustly communicated with them. The result of this analysis is the information flow architecture depicted in Fig. \ref{fig:blackboxflow}.
% list the output data: dst, dev magnitude and direction
% warn and crit states
% list the input data: pos, vel, crs, path
The inputs necessary to relay that information were then determined

% Black box info flow chart
\begin{figure}[ht] \label{fig:blackboxflow} \centering
    \includegraphics[width=6.5in]{./figs/blackbox_flowchart.png}
    \caption{High level information flow architecture in and out of the GUI}
\end{figure}

%%%% Made 2 GUIs
%% Monolith
From the outset, a primary design goal was to minimize the amount of visual and cognitive effort required on the part of the driver for determining whether course and speed corrections are necessary, and if so, what they are. Facilities for accepting driver-input operational parameters must therefore be obscured during the driving task, yet easily accessible on the fly. In addition, a clean and minimal visual presence ensures that a passing glance is sufficient to check on distance and deviations. When following very closely, a follower will need to anticipate upcoming turns without being able to see the leader actually turn, so course information---specifically, the leader's course relative to that of the follower---will be needed.  These were the fundamentals driving the GUI development at the outset.

%% Earth
Since a significant end use case involves military convoys, feedback was sought from personnel in the Armed Forces. One primary criticism was the lack of visual stimuli by which to reconcile the screen output with what the user sees around them. To remedy this, it was suggested that satellite imagery be incorporated into the background of the information already displayed on the screen. As the directly contradicted the clean, distraction-free nature of the prototype already developed, it was determined that another version needed to be constructed following these new design principals, and that the two GUI's should be juxtaposed. In determining what software package to use to supply this, a trade study was performed and the resulting candidates were narrowed to Quantum GIS and Earth (by Google). The maturity, user-base and documentation on representing data with the Keyhole Markup Language (KML) ultimately made Google Earth the favored tool. As elaborated upon in Section \ref{sec:interp}, the addition of satellite imagery made the user highly aware of the update rate of each piece of information displayed spatially, necessitating the incorporation of data smoothing techniques.

%%%%%%%%%%%%%%%%%%%%%%
% Interpolator Section
\section{Real-Time Interpolation} \label{sec:interp}

%%%%% introductory
% TODO better segway, why linear interpolation used (speed?)
Since the end goal is to display information that has been received rather than predict future states, the newest and second newest measurments are fewest points required to do a live interpolation. With this, a continuous-time linear interpolation of the measurment any instant between those two times is possible. By making more data points available and considering the type of data in question, more accurate interpolation may be possible. However, due to speed and efficiency, the linear interpolation is preferable in this situation. All values which are displayed in the GUI (listed in Sect. \ref{sec:guiintro}) are passed through the interpolation algorithm.

%%%%% general algorithm
%% formula
\begin{align} \label{eq:interp}
    x(t) &= (x_1 - x_0) \frac{ t - t_0 } { t_1 - t_0 } + x_0
\end{align}

The general form of the linear interpolation to obtain a value $x$ at time $t$ which lies between values $x_0$ and $x_1$ corresponding to times $t_0$ and $t_1$, respectively, is given by Eq. \ref{eq:interp}.
%%%% data-type specific
For two dimensional positions, this procedure is carried out on both the East and North coordinates. 
%% angle
Angles are a different matter. The course dimension contains an inherent discontinuity due to `wrapping' at the North axis. A course change of $-1^\circ$ may result in a measurment change of $-359^\circ$, which if naively interpolated would result in a complete spin over a full timestep, ending at essentially the same location as the beginning. For this reason, the angles must be occasionally be resolved (i.e., when $|x_1 - x_0| > 180^\circ$ ) by adding $360^\circ$ to the lowest value. For example, values of $(x_0, x_1) = (0.5^\circ, 359.5^\circ)$ would then become $(x_0, x_1) = (360.5^\circ, 359.5^\circ)$ .
%% path
For the path to be interpolated, 

%% time update
On the first measurment update, the value and CPU time at which it arrived are stored. It is important that CPU time is recorded upon arrival rather than upon processing or sending, as the goal of this process is to obscure lags incurred during calculation or radio transmission. The end result is that the user is presented with data which changes at a consistent, even frequency, regardless of whether multiple sensors take varying amounts of time to relay data.

Upon each subsequent measurement update, the previous two entities are stored moved to slots for old data $(x_0, t_0)$ and the new value is stored along with present CPU time. An interpolation object representing Eq. \ref{eq:interp} is created with the present data so that between times $t_0$ and $t_1$ an input $t$ will yield the respective measurement $x$. Any interpolation thread which is still running is then stopped, and a new one spawned. This thread the iteratively calculates data between $x_0$ and $x_1$, then waits a period of time corresponding to the desired frequency, repeating until a new measurement update occurs.

%%%%% transition to data dissemanation
The effect this had upon readability and being able to intuitively interpret data was positive. Even though it was initially intended to smooth movement of satellite imagery and low sensor frequencies, it became desirable to investigate the benefits on the monolithic GUI. Rather than rewrite the smoothing tool for that purpose, it was modularized as described in Sec. \ref{sec:datadiss}, to distribute data agnostically.

%%%%%%%%%%%%%%%%%%%%
% Data Dissemenation
\section{Data Dissemenation} \label{sec:datadiss}

%%%% Intro 

%%%% Qt Signals/Slots - REDO
The Qt framework used to generate the GUI from common building blocks has an internal message passing scheme similar to a publisher/subscriber model, using instead what are called signals and slots. For instance, the main window widget alerts the render area to the left when a spinbox in the options has been changed via a signal/slot by passing a boolean value. All data coming into the GUI from MOOS passes through an interface that bridges MOOS with two signal/slot pairs: one for the relative path list and for the follower velocity. In this way GUI inputs can be made agnostic to the middleware used, requiring only a simple widget be written in order to be hooked up to a new data stream.

%%%% MOOS Messages - input to GUI
Figure \ref{fig:blackboxflow} depicts the predefined inputs and outputs of the GUI. The primary message passing architecture used to deliver data to the GUI, as depicted in Fig. \ref{fig:blackboxflow}, was the Mission Oriented Operating Suite (MOOS), as developed by \cite{moos}. The GUI was initially developed using postprocessed data collected from an Prowler ATV automously following an Infiniti G35 using the same positioning and radio setup described in Sect. \ref{sec:hardware}. This is made possible by the playback feature of the MOOS framework, which is used in live operation to send raw data between the GPS receiver and the DRTK, TDCP and DAF algorithms, and then to the GUI middleware interface.

%%%% Specific to Earth GUI
Due to the large and 
%% passing middleware object instance references
%% KML server

%%%%%%%%%%%%%%
% Calculations
\section{Calculations} \label{sec:guicalc}

% UTM coordinates - REDO
When displaying data on a flat, rectangular screen, it becomes desirable to utilize a coordinate system more suited to cartesian calculations than Latitude-Longitude-Altitude (LLA), one which employs standard metric units of length. Whenever rectangular coordinates are necessary the Universal Transverse Mercator (UTM) east and north representations of global positions are used. The conversions between the LLA and UTM coordinate systems are outlined in \cite{projections}.

%%%% Calculating the lateral error
The most crucial calculations are performed upon the vector of relative path points, of which two particular points are the subject of great attention. In Fig. \ref{fig:pathpts} the point $(x_1,y_1)$ represents the nearest (i.e., lowest distance to the origin) which also lies behind the antenna of following vehicle, meaning the vector from the origin and the follower's velocity vector form an obtuse angle. The DAF algorithm sorts and outputs points such that this will be the last in the vector, and prior to this will be the nearest point in front of the vehicle's antenna, named $(x_2,y_2)$ in Fig. \ref{fig:pathpts}. The path is assumed to be straight between these two points. The lateral deviation of a follower at $(x_0, y_0)$ from the path occurs here and is defined as the length of a line perpendicular to the path line, which it intersects at $(x_3,y_3)$---used later for forward spacing calculation. Note that depending on path shape and timing, $(x_3,y_3)$ may not necessarily lie between $(x_1,y_1)$ and $(x_2,y_2)$. Since the DAF algorithm will output in East-North coordinates translated to the follower's position, $(x_0, y_0)=(0,0)$ at all times. The formulation of the lateral deviation is then given by Eq. \ref{eq:laterr} \cite{laterrformula}, with the underlying assumption being that the GPS antenna is placed on the lateral center of the vehicle. Once this value has been determined, it may simply be compared against user-input threshold values for warning and criticall states to determine whether to issue an alert as discussed in Secs. \ref{sec:finaldes_monolith} and \ref{sec:finaldes_earth}.

% path lines and points of importance
\begin{figure}[ht] \label{fig:pathpts} \centering
    \includegraphics[width=3in]{./figs/path_points.png}
    \caption{Points used to calculate distance and deviation}
\end{figure}

% Lateral error formula
\begin{align} \label{eq:laterr}
    e &= \frac{ | (x_2 - x_1)(y_1 - y_0) - (x_1 - x_0)(y_2 - y_1) | } { \sqrt{ (x_2 - x_1)^2 + (y_2 - y_1)^2 } }
\end{align}

%%%% Calculating the distance
Next, a measure of the curvilinear distance separating the leader and follower is necessary for collision avoidance purposes. To do this, it is assumed that the follower will adhere to the path, and that the current position of the follower lies along rearmost path line at point $(x_3, y_3)$ where $m_{12}$ and $m_{03}$ represent the slopes of the rearmost path line and the perpendicular deviation line, respectively. Finding this point is possible by use the relations in Eqs. \ref{eq:devprojx} and \ref{eq:devprojy}. The line segment between it and $(x_1,y_1)$ is removed, and the magnitudes of all other lines are summed to obtain the curvilinear spacing between the two GPS antennae. 

% projection of deviation point
\begin{align} 
    x_3 &= \frac{ m_{12} x_1 - m_{03} x_0 + y_0 - y_1 } { m_{12} - m_{03} } \label{eq:devprojx} \\
    y_3 &= m_{03} (x_3 - x_0) + y_0 \label{eq:devprojy}
\end{align}

Ultimately, a safety estimate for forward spacing at any given time is to be compared to this distance and used to determine alert status as described in Secs. \ref{sec:finaldes_monolith} and \ref{sec:finaldes_earth}. For this estimate, a few assumptions are made about the braking behavior: the vehicle in question is equipped with a braking system which is able to keep friction forces between the road in tires in the static regime (anti-lock brakes), the braking system is capable of maintaining peak longitudinal forces during negative acceleration, and the driver has an instantaneous reaction time. At each time update, a minimum stopping distance is calculated based on these assumtions for two different road surfaces with user-input coefficients of friction corresponding to the warning and critical states, where $\mu_{crit}<\mu_{warn}$ resulting in $d_{stop, min}^{crit} < d_{stop, min}^{warn}$. This relation is given in Eq. \ref{eq:stopdist}, where $\mu$  is the combined coefficient of static friction between the terrain surface and the tires,  $|\bar{v}|$ is the magnitude of ground-plane velocity, and $g$ is the acceleration due to gravity.The previously stated assumptions are made in order to reduce the number of user-input values for the distance safety calculation to these two alone. The default values are for a low-friction surface such as gravel ($\mu_{crit}=0.4$), and a `critical' state---when the present minimum stopping distance is than that for a typical asphalt roadway($\mu=0.7$). 
% TODO add citation for mu values
% stopping distance equation (mu)
\begin{align} \label{eq:stopdist}
    d_{stop, min} &= \frac {|\bar{v}|^2} {2 \mu g}
\end{align}


%%%%%%%%%%%%%%%%%%%%%%
% Final Design Section
\section{Final Design} \label{sec:finaldes}
In relaying alerts for deviation and distance

%%%% Monolith %%%%
\subsection{Monolithic GUI} \label{sec:finaldes_monolith}
The final form of the monolithic GUI can be seen in Figures \ref{fig:finaldesdriv_monolith} and \ref{fig:finaldesopts}. Immediately noticeable is the tabbed `command interface' on the right of the window. It contains two primary tabs: one for display of important data (forward spacing, lateral deviation, and follower velocity), and a tab for entry of operational parameters. The view is always oriented such that `up' on the screen corresponds to the positive longitudinal axis of the following vehicle. The orientation of the lead vehicle (represented with a simple square icon containing an arrow for its positive longitudinal axis) is then always shown relative to the follwing vehicle. So if the leader is shown pointing to the right, the direction of its motion is then parallel to the follower's lateral axis and in the positive direction. A third tab containing controls for manually manipulating the orientation was created, however this was intended only for development purposes and is unavailable to the end user, to prohibit distraction during the driving task. It should be noted as well that all vehicle coordinate frames are in accordance with Society of Automotive Engineers' Vehicle Axis System \cite{vdbook}.

%%%% Renderarea
%% alerts
% dev
% dst

% the driver screen
\begin{figure}[ht] \centering \label{fig:finaldesdriv_monolith}
    \includegraphics[width=6.5in]{./figs/final_design_data.png}
    \caption{Final Design --- Driver view}
\end{figure}

%% options screen - REDO
There is always the option to change operational parameters, using the screen depicted in Figure \ref{fig:finaldesopts}, which are primarily the lateral deviation thresholds, following distance $\mu$ thresholds, for the monolithic and the maximum distance to display onscreen during fixed-scale mode. When the option for to always display the lead vehicle is enabled, the maximum following distance becomes the minimum value, and whenever the direct distance to the follower exceeds this, the screen is scaled to include it in the range semicircle.

% the option screen
\begin{figure}[ht] \centering \label{fig:finaldesopts}
    \includegraphics[width=5in]{./figs/final_design_opts.png}
    \caption{Final Design --- Setting of operational parameters }
\end{figure}

%%%% Earth %%%%
\subsection{Google Earth GUI} \label{sec:finaldes_earth}

With the Earth incarnation, a more divided approach was taken. Since the presence of satellite imagery drastically increases the amount of  visual stimuli, it was decided that the user should be able to enter view-only mode and be rid of any objects designed for input once operational parameters had been settled upon. To this end, the command interface is liberated from the central display screen and forms its own window outside the Earth environment. The command interface is where all mathematical calculations are carried out; it is simpler to get the current values of any operational parameters needed wihout incurring additional overhead since their values are also attributes of the same object.

%%%% alerts
\begin{figure}[ht] \centering \label{fig:earth_dst}
    \includegraphics[width=6.5in]{./figs/earth_slow.png}
    \caption{Following driver being signalled in Google Earth to correct left and slow}
\end{figure}

%% dev

%% dst


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   Chapter 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Experimentation}
\label{chap:exper}

%%%%%%%%%%%%%%%%%%%%%%%%
% Hardware Setup Section
\section{Hardware Setup} \label{sec:hardware}

All experimental data was taken using Novatel Propak v3 GPS receivers with pinwheel antennas, identical to those used in \cite{scottthesis}. All positioning computation was conducted on an Apple MacBook Pro Laptop running Ubuntu Linux 12.04.1 in a Parallels virtual machine in the rearmost vehicle. Novatel data was relayed directly from receivers in other vehicles to the positioning computer through the use of XTend-PKG $1~W,~900~MHz$ radio modems connected via RS232-USB adapters. This eliminated the need for additional computers, which was found to introduce unacceptable latency into the system. In this manner, a single central hub was able to host the MOOS database while controlling all receivers and data flow to all position algorithms for multiple vehicle testing.

\begin{figure}[ht] \centering \label{fig:hardwarelead}
    \includegraphics[width=6.5in]{./figs/leader_hardware.png}
    \caption{Equipment used in the leading vehicle}
\end{figure}

% data collection
The stream of available data may be divided into two categories: raw GPS measurements used to compute a relative path online, and the measurements coming either the receiver or DAF algorithm which is displayed on-screen. When conducting experimental trials for formal analysis, the latter is recorded in order to capture exactly what was displayed to the following driver and examine their performance. The former is excluded in order to reduce the volume of data throughput and increase computing efficiency, as following distance and lateral path deviation are derived from the relative path and follower velocity alone. 
However, during the develop-test-refine cycle, the inverse is true; raw GPS measurements alone are recorded (again, neglecting other data for efficiency). This is then replayed to simulate online operation as algorithms are tuned.

\begin{figure}[ht] \centering \label{fig:hardwarefoll}
    \includegraphics[width=6.5in]{./figs/follower_hardware.png}
    \caption{Equipment used in the following vehicle}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What tests were performed
\section{Testing} \label{sec:test}

%%%% Lane change replication
\subsection{Lane Change Replication} \label{sec:lanechange}

In determining the usefulness of any tool, it is highly desirable to devise a test which yields concise results that are either completely positive or negative. To this end, a maneuver common in the characterization of vehicle dynamics, the lane change, was used in a situation in which the maneuver could be replicated properly or improperly. 





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   Chapter 4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Error Propagation in Convoys}
\label{chap:errprop}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   Chapter 5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusions}
\label{chap:concl}


\section{Future Work}
\label{sec:futwork}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   Bib
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{asmems4}
\bibliography{thesis}

\nocite{travisdiss}
\nocite{travisshort}
\nocite{calgary}

% \bibitem{platoon} M. E. Cannon, C. Basnayake, S. Syed, and G. Lachapelle. ``Precise gps sensor subsystem for Vehicle Platoon  Control." In Proceedings of ION GPS/GNSS 2003 Conference. pp 213-224, 2003.

\end{document}